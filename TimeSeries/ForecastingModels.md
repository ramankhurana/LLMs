| Model | Developed By | Model Variations / Size | Primary Usage |
|-------|--------------|-------------------------|---------------|
| [Chronos](https://github.com/amazon-science/chronos-forecasting) | Amazon Web Services (AWS) | Chronos-Bolt (T5-based), Chronos-Large | Zero-/few-shot forecasting, anomaly detection |
| [TimeGPT](https://www.nixtla.io/docs/) | Nixtla | TimeGPT-1, TimeGPT-2 | Forecasting for business, energy, retail, etc. |
| [Moirai](https://arxiv.org/abs/2410.10469) | Salesforce AI Research | Moirai-MoE-Small, Moirai-MoE-Base | Long-horizon forecasting using context-aware architecture |
| [TimesFM](https://github.com/google-research/timesfm) | Google Research | TimesFM-1 (200M parameters) | Forecasting, imputation, general-purpose TS tasks |
| [Time-XL](https://arxiv.org/abs/2402.03988) | Microsoft Research | Time-XL (multi-scale transformer) | Forecasting, classification, anomaly detection |
| [Lag-Llama](https://github.com/time-series-foundation-models/lag-llama) | Morgan Stanley, ServiceNow, Université de Montréal, Mila, McGill University | Lag-Llama (open-source, 1.3B params) | Zero-shot univariate forecasting |
| [MOMENT](https://github.com/moment-timeseries-foundation-model/moment) | University of Washington and collaborators | MOMENT (ensemble and standalone models) | Forecasting, classification, anomaly detection |
| [TimeFound](https://arxiv.org/abs/2503.04118) | NUS, Ant Group, Zhejiang University | TimeFound-L (2.4B params) | Zero-shot and fine-tuned forecasting |
| [Toto](https://www.datadoghq.com/blog/datadog-time-series-foundation-model/) | Datadog | Toto (internal sizes not disclosed) | Operational/observability forecasting |
| [Time-MoE](https://aihorizonforecast.substack.com/p/time-moe-billion-scale-time-series) | Open-source community | 2.4B parameters (Mixture of Experts) | Zero-shot forecasting |
| [ETSformer](https://arxiv.org/abs/2202.01381) | Huawei Noah’s Ark Lab | ETSformer-L, ETSformer-S | Forecasting with seasonal/trend modeling |
| [Pathformer](https://arxiv.org/abs/2402.05956) | HKUST | Pathformer (multi-scale attention) | Multi-horizon forecasting |
| [TimeDiT](https://arxiv.org/abs/2409.02322) | UCLA | TimeDiT (Diffusion-based architecture) | Forecasting, imputation, anomaly detection |
| [GTT (General Time Transformer)](https://dl.acm.org/doi/10.1145/3627673.3679931) | UIUC | GTT (encoder-only design) | Multivariate zero-shot forecasting |
