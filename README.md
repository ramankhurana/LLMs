# LLMs
All information about LLMs available in open and closed source

| Model Series | Model Version | Number of Parameters | Open Source & License Terms | Features | Comment | Date of Release | Context Length | Pricing |
|--------------|---------------|----------------------|-----------------------------|----------|---------|-----------------|----------------|---------|
| **LLaMA**    | LLaMA 2       | 7B, 13B, 70B         | Custom License (research and commercial use with restrictions) | General-purpose language understanding and generation |         | July 2023        | 4,096 tokens   | Free for approved users |
| **LLaMA**    | LLaMA 3.1     | 8B, 70B, 405B        | Custom License (research and commercial use with restrictions) | Advanced language tasks, coding, multilingual support |         | April 2024       | Up to 128,000 tokens | Free for approved users |
| **Mistral**  | Mistral 7B    | 7.3B                 | Apache 2.0                  | General-purpose language tasks; outperforms larger models on various benchmarks |         | July 2024        | 128,000 tokens | Free |
| **Mistral**  | Mixtral 8x7B  | Mixture of Experts (MoE) model with 7B active parameters per expert | Apache 2.0 | Efficient handling of diverse tasks through MoE architecture |         | July 2024        | 128,000 tokens | Free |
| **Mistral**  | Mistral Large 2 | 123B               | Apache 2.0                  | High-performance model for complex language tasks |         | July 2024        | 128,000 tokens | Free |
| **Falcon**   | Falcon 7B     | 7B                   | Apache 2.0                  | Language understanding and generation; trained on web data |         | May 2023         | 2,048 tokens   | Free |
| **Falcon**   | Falcon 40B    | 40B                  | Apache 2.0                  | Enhanced performance for various NLP tasks |         | May 2023         | 2,048 tokens   | Free |
| **Falcon**   | Falcon 180B   | 180B                 | Apache 2.0                  | Competitive with state-of-the-art models in language tasks |         | December 2023    | 2,048 tokens   | Free |
| **GPT-NeoX** | GPT-NeoX-20B  | 20B                  | Apache 2.0                  | Autoregressive language generation for various NLP tasks |         | April 2022       | 2,048 tokens   | Free |
| **MPT**      | MPT-7B        | 7B                   | Apache 2.0                  | Commercially usable language model with extended context lengths |         | May 2023         | 8,192 tokens   | Free |
| **MPT**      | MPT-30B       | 30B                  | Apache 2.0                  | Enhanced performance with longer context handling |         | June 2023        | 8,192 tokens   | Free |
| **RedPajama**| RedPajama-INCITE-7B | 7B            | Apache 2.0                  | Instruction-tuned and chat models for diverse NLP tasks |         | July 2023        | 2,048 tokens   | Free |
| **StarCoder**| StarCoderBase | 15.5B                | OpenRAIL-M                  | Code-focused language model for programming tasks |         | May 2023         | 8,192 tokens   | Free |
| **Molmo**    | Molmo-70B     | 70B                  | Apache 2.0                  | Multimodal capabilities; interprets images and interacts through chat |         | August 2024      | 4,096 tokens   | Free |
| **Molmo**    | Molmo-1B      | 1B                   | Apache 2.0                  | Optimized for mobile devices; supports multimodal interactions |         | August 2024      | 4,096 tokens   | Free |
| **GPT**      | GPT-4o        | Not publicly disclosed | Proprietary              | Advanced language understanding and generation |         | March 2024       | 8,192 tokens   | Subscription-based |
| **Gemini**   | Gemini 1.0 Nano | Not publicly disclosed | Proprietary              | Optimized for mobile devices; efficient performance |         | November 2023    | Not publicly disclosed | Subscription-based |
| **Gemini**   | Gemini 1.5 Pro | Not publicly disclosed | Proprietary              | Enhanced performance for complex tasks |         | February 2024    | Not publicly disclosed | Subscription-based |
| **Gemini**   | Gemini 1.0 Ultra | 1.5 trillion      | Proprietary                | High-end model with extensive capabilities |         | November 2023    | Not publicly disclosed | Subscription-based |
| **Claude**   | Claude 3.5    | Not publicly disclosed | Proprietary                | Improved reasoning and language understanding |         | January 2024     | 100,000 tokens | Subscription-based |
| **Nova**     | Nova Pro      | Not publicly disclosed | Proprietary                | Tailored for various applications; scalable performance |         | December 2023    | Not publicly disclosed | Subscription-based |
| **Phi**      | Phi-3         | Not publicly disclosed | Proprietary                | Advanced reasoning and language capabilities |         | March 2024       | Not publicly disclosed | Subscription-based |
| **Qwen**     | Qwen 2.5      | 0.5B to 72B          | Proprietary                 | Models ranging in size for diverse applications |         | April 2024       | Not publicly disclosed | Subscription-based |
| **Nemotron** | Nemotron-4 340B | 340B               | Proprietary                 | High-parameter model for complex tasks |         | May 2024         | Not publicly disclosed | Subscription-based |
| **Grok**     | Grok 2        | Not publicly disclosed | Proprietary                 | Enhanced capabilities for various applications |         | June 2024        | Not publicly disclosed | Subscription-based |
| **Fugaku-LLM** | Fugaku-LLM-13B | 13B               | Proprietary                 | Japanese language model for diverse tasks |         | July 2024        | Not publicly disclosed | Subscription-based |
| **DeepSeek** | DeepSeek-V3   | Not publicly disclosed | Proprietary                 | Advanced LLM with enhanced capabilities |         | August 2024      | Not publicly disclosed | Subscription-based |
| **Orca**     | Orca          | Not publicly disclosed | Proprietary                 | Progressive learning model with complex reasoning |         | September 2024   | Not publicly disclosed | Subscription-based |
| **GLaM**     | GLaM          | Not publicly disclosed | Proprietary                 | Efficient scaling model with mixture-of-experts architecture |         |
::contentReference[oaicite:0]{index=0}
 
